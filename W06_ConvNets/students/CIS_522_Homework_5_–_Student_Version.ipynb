{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIS_522_Homework_5_â€“_Student_Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2kPrtVyXtaP"
      },
      "source": [
        "# CIS-522 Week 5 Homework\n",
        "\n",
        "__Instructor__: Konrad Kording\n",
        "\n",
        "__Content creators:__ Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava\n",
        "\n",
        "__Content reviewers:__ Ann-Katrin Reuel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_VqTwG09NEn",
        "cellView": "form"
      },
      "source": [
        "#@markdown What is your Pennkey and pod? (text, not numbers, e.g. bfranklin)\n",
        "my_pennkey = '' #@param {type:\"string\"}\n",
        "my_pod = 'Select' #@param ['Select', 'upain', 'ah-damn-optimizer', 'backpropagandists', 'backpropers','excel-erators','GAN-gsters','han-not-solo','hufflefluffs','lets-taco-bout-it','natural-networkers','pytorture','sigmoids','strong-signals','the-denominators','the-travellers', 'the-weekenders', 'tomorrows-incredibles', 'brute-force']\n",
        "my_email = '' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# start timing\n",
        "import time\n",
        "try:t0;\n",
        "except NameError: t0 = time.time()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pty3-UGXrIu"
      },
      "source": [
        "In this homework, you will implement an image classification problem on a much more complex Dataset, the **CIFAR 10 Dataset**. We will train two models: a fully connected network and a convolutional network and observe the difference in their performance on images. We will further try to visualize the features learned by some of our convolutional layers in the CNN and answer some questions about ethics and our pod members!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPBNHacqXkrC",
        "cellView": "form"
      },
      "source": [
        "# @title Run this cell for imports.\n",
        "\n",
        "# imports\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.utils import make_grid\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from time import sleep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mWvVdyBWaQ2",
        "cellView": "form"
      },
      "source": [
        "# @markdown Figure Settings\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline \n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS8R1OGeoydf",
        "cellView": "form"
      },
      "source": [
        "#@markdown Device Settings<br> It should print 'cuda', if not change your runtime to GPU.\n",
        "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qzHTBpz9hy4"
      },
      "source": [
        "# Part 0. Exploring the Dataset and Basic Functions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqUPARL31PZM"
      },
      "source": [
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The classes in the dataset are:<br>\n",
        "['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYU7E22k0KAj"
      },
      "source": [
        "Let's download the dataset and build our datatloaders. Set the **BATCH_SIZE** for the dataloaders yourself. \n",
        "\n",
        "The three dataloaders are accessible by the variables *trainloader*, *validationloader* and *testloader*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxh6d3e-l0xo"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "# TODO: set Batch size for dataloaders\n",
        "BATCH_SIZE = ...\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# splitting the testset into testset and validationset, with a 80:20 ratio\n",
        "validationset, testset = torch.utils.data.random_split(testset, [8000, 2000])\n",
        "\n",
        "validationloader = torch.utils.data.DataLoader(validationset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDB8YVwV9b6q"
      },
      "source": [
        "Let us check the sizes of our three sets and print some images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqnof9BT9bmf"
      },
      "source": [
        "print(len(trainset))\n",
        "print(len(validationset))\n",
        "print(len(testset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rvwTZenBw4C"
      },
      "source": [
        "# function to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[0:4]))\n",
        "print('    \\t\\t'.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbXSt-fJg4Dy"
      },
      "source": [
        "Now let's write a train function which basically trains any network by running epochs and also evaluates the results on our validation set in every epoch. We will keep tunable hyperparameters as the parameters for the function so that we can directly tweak them and call the function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax6tvOYamPHy"
      },
      "source": [
        "def train(model, device, train_loader, validation_loader, epochs, criterion, optimizer):\n",
        "  # Params:\n",
        "  #   model-> instance of your model which extends nn.Module class\n",
        "  #   device -> it is set to cuda already and is already stored in a variable called *device*\n",
        "  #   train_loader -> dataloader for train dataset, already stored in a variable called *trainloader*\n",
        "  #   validation_loader -> dataloader for validation dataset, already stored in a variable called *validationloader*\n",
        "  #   epochs -> number of epochs for training, you are expected to experiment and play around with this\n",
        "  #   criterion -> the loss function which you decide to use\n",
        "  #   optimizer -> optimizer for your gradient descent, do not forget to set an appropriate learning rate\n",
        "  #  Returns:  train_loss, train_accuracy, validation_loss, validation_accuracy, all of these are lists storing the values \n",
        "\n",
        "    train_loss, validation_loss = [], []\n",
        "    train_acc, validation_acc = [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.\n",
        "        correct, total = 0, 0 \n",
        "        # TODO: train on the train dataset\n",
        "        with tqdm(train_loader, unit='batch') as tepoch:\n",
        "            tepoch.set_description('Training: ')\n",
        "            ...\n",
        "            \n",
        "\n",
        "                \n",
        "        # TODO: evaluate on validation data\n",
        "        model.eval()\n",
        "        running_loss = 0.\n",
        "        correct, total = 0, 0 \n",
        "        with tqdm(validation_loader, unit='batch') as tepoch:\n",
        "            tepoch.set_description('Validation: ')\n",
        "            ...\n",
        "         \n",
        "    \n",
        "    return train_loss, train_acc, validation_loss, validation_acc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUkhShTOm00R"
      },
      "source": [
        "Now, let's write a test function which returns the accuracy of a trained model on the test dataset, given the testloader. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJC7BLkSm2_2"
      },
      "source": [
        "def test(model, device, data_loader):\n",
        "  # Params:\n",
        "  #   model-> instance of your trained model which extends nn.Module class\n",
        "  #   device -> it is set to cuda already and is already stored in a variable called *device*\n",
        "  #   data_loader -> dataloader for test dataset, already stored in a variable called *testloader*\n",
        "  # Returns:\n",
        "  #   accuracy(float)-> percentage of correct predictions made by your trained model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader:\n",
        "      # TODO: fill in the test function\n",
        "      ...\n",
        "\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uvt-pw0pqxn"
      },
      "source": [
        "Below, we have provided a function to plot your train loss, test loss, train accuracy and test accuracy, during the training process. They take in the arguments which were the four lists returned by your train function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeCIzBG1ppkc"
      },
      "source": [
        "# code to plot loss and accuracy\n",
        "def plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc):\n",
        "    epochs = len(train_loss)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    ax1.plot(list(range(epochs)), train_loss, label='Training Loss')\n",
        "    ax1.plot(list(range(epochs)), validation_loss, label='Validation Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Epoch vs Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(list(range(epochs)), train_acc, label='Training Accuracy')\n",
        "    ax2.plot(list(range(epochs)), validation_acc, label='Validation Accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.set_title('Epoch vs Accuracy')\n",
        "    ax2.legend()\n",
        "    fig.set_size_inches(15.5, 5.5)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTosRRlnu1q"
      },
      "source": [
        "# Part 1: FeedForward Neural Network\n",
        "\n",
        "In this section, we will implement a feed-forward neural network that can classify the images in the CIFAR 10 dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9QkFYgn1U2V"
      },
      "source": [
        "Here, we define our FFN class which will consists of all the layers and the forward function. Feel free to play around by introducing different types of regularization, architectures, learning rates, epochs, and batch sizes, in order to achieve maximum accuracy. **However, you are not allowed to use convolutional layers in the model yet.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVF8XNgSIi3t"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Re6fjrqmNxO"
      },
      "source": [
        "class FFN(nn.Module):\n",
        "    ...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSbgt3aZInJm"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0tjSGwx2K-3"
      },
      "source": [
        "Now, let us intantiate our FFN class, define the loss, the optimizer and call the train function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21cwe-dr9QX"
      },
      "source": [
        "# TODO: set criterion, optimizer and other hyperparameters and train\n",
        "net1 = FFN().to(device)\n",
        "criterion = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "num_epochs = ..\n",
        "train_loss, train_acc, validation_loss, validation_acc = train(net1, device, trainloader, validationloader, num_epochs, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuZ8tmtIqIq"
      },
      "source": [
        "## Training Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5k3Ng4X3Gc2"
      },
      "source": [
        "Now, let us plot the train and validation curves. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXxKn6tJsYEK"
      },
      "source": [
        "plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_S9sqmcIurm"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMbbT8jU3MrQ"
      },
      "source": [
        "And test our trained network on the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV8LUhKOt53H"
      },
      "source": [
        "test(net1, device, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKFjXo2_H9aP"
      },
      "source": [
        "And fill up the accuracy value you get. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbasJZLmGaxR"
      },
      "source": [
        "ffn_accuracy = test(net1, device, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLS6YvCA8_aE"
      },
      "source": [
        "Try to reach a test accuracy of atleast 45% with the Fully Connected Network. Bonus points if you can go over 50%!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdSDRIxu_Y56"
      },
      "source": [
        "## Discuss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5J-Qy5e_3kfb"
      },
      "source": [
        "#@markdown Discuss the hyperparameters and architectures you chose. Which model led to the best performance? Why? (200 words)\n",
        "import time\n",
        "try:t1;\n",
        "except NameError: t1 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1F1t6sv_q2K"
      },
      "source": [
        "ffn_discussion = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls3EKr4846PS"
      },
      "source": [
        "# Part 2: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS71XpEt8yDA"
      },
      "source": [
        "Now, design a convolutional neural network, for the same problem. Again, try to play around with various architectures, regularizations, activations, learning rates, optmizers and try to leverage the power of CNNs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olHo2tLEDAoe"
      },
      "source": [
        "**Note:** Put all your convolutional layers and activations in the first Sequential module, instead of defining different layers and making an explicit forward pass.\n",
        "Similarly, add all the subsequent fully connected layers in the second Sequential module, which comes after flattening the output from the convolutional layers.\n",
        "\n",
        "**Do not change the forward pass code here.** \n",
        "<br>\n",
        "This will help you run the next section on Visualization on your chosen architecture and visualize the feature maps of different convolutional layers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8kIqEMUI5le"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVtNorDY71Lm"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    ...\n",
        "        \n",
        "\n",
        "    # DO NOT CHANGE THE FORWARD PASS\n",
        "    def forward(self, x):\n",
        "\n",
        "        # feed x into model!\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4d2BS0XI7zV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty9Oygt8Enwe"
      },
      "source": [
        "Calling the train function for the ConvNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cz4x38y71Lo"
      },
      "source": [
        "# TODO: fill the hyperparameters and train the model\n",
        "net2 = CNN().to(device)\n",
        "criterion = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "num_epochs = ...\n",
        "train_loss, train_acc, validation_loss, validation_acc = train(net2, device, trainloader, validationloader, num_epochs, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynl60dMXI-10"
      },
      "source": [
        "## Training Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t__-RhyhE7C1"
      },
      "source": [
        "Now plot your training curves!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_uJupIo71Lp"
      },
      "source": [
        "plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnYNazivJLhd"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhMLzCl0E_DY"
      },
      "source": [
        "Test your trained model on the test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ergUuc71Lq"
      },
      "source": [
        "test(net2, device, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88BR57f7IRMO"
      },
      "source": [
        "And fill in the accuracy here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLu7fsQeHvly"
      },
      "source": [
        "cnn_accuracy = test(net2, device, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_8JrjqgFE9S"
      },
      "source": [
        "Try to reach an accuracy of at least 52 %. Bonus points for anything above 65 %!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXz_yDqvJT7c"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aGOLsp1d31Yd"
      },
      "source": [
        "#@markdown Discuss the hyperparameters and architectures you chose. Which model led to the best performance? Did your CNN outperform your FFN? Why? (200 words)\n",
        "import time\n",
        "try:t2;\n",
        "except NameError: t2 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mx3pslXHukJ"
      },
      "source": [
        "cnn_discussion = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "739NtnJJJXKL"
      },
      "source": [
        "# Part 3: Visualizations: What do the features look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwFOE6eeYP_e",
        "cellView": "form"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "input_img=images[random.randrange(0,BATCH_SIZE,1)].unsqueeze(0)\n",
        "img_original=input_img.squeeze().permute(1,2,0).numpy()\n",
        "\n",
        "\n",
        "Layer_Name= 3 #@param {type:\"slider\", min:1, max:54, step:1}\n",
        "Layer_Name=str(Layer_Name)\n",
        "Num_Filters = 2 #@param {type:\"slider\", min:2, max:64, step:1}\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "def temp_rem(model,key,input_img):\n",
        "    model.eval()\n",
        "    flag=0\n",
        "    alt_=[]    \n",
        "    for search in model._modules['features']._modules.keys():\n",
        "        if flag==1:\n",
        "            break\n",
        "        if key==search:\n",
        "            flag=1\n",
        "        alt_.append(model._modules['features']._modules[search])\n",
        "    return torch.nn.Sequential(*alt_).to(device)(input_img.to(device)).squeeze().detach().cpu().numpy()\n",
        "\n",
        "def plot(data,Num_Filters,img_original):\n",
        "    import matplotlib.pyplot as plt\n",
        "    i=0\n",
        "    flag=0\n",
        "    #print(len(data))\n",
        "    if Num_Filters>len(data):\n",
        "        print(\"Please set Num_Filters parameter less than or equal to the number of filters present in the layer ({} in this case)\".format(len(data)))\n",
        "        return\n",
        "    if Num_Filters<8:\n",
        "        fig, ax = plt.subplots(1,Num_Filters)\n",
        "        for col in ax:\n",
        "            if flag==0:\n",
        "                col.imshow(resize(img_original,(256,256)))    \n",
        "                col.set_xticklabels([])\n",
        "                col.set_yticklabels([])\n",
        "                \n",
        "                flag=1\n",
        "            else:\n",
        "                col.imshow(resize(data[i],(256,256)))\n",
        "                col.set_xticklabels([])\n",
        "                col.set_yticklabels([])\n",
        "                \n",
        "            i=i+1\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    i=0    \n",
        "    if Num_Filters<16:\n",
        "        ncols=4\n",
        "    else:\n",
        "        ncols=8\n",
        "\n",
        "    nrows=Num_Filters//ncols\n",
        "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "    for rows in ax:\n",
        "        for cols in rows:\n",
        "            if flag==0:\n",
        "                cols.imshow(resize(img_original,(256,256)))    \n",
        "                cols.set_xticklabels([])\n",
        "                cols.set_yticklabels([])\n",
        "                flag=1\n",
        "            else:\n",
        "                cols.imshow(resize(data[i],(256,256)))\n",
        "                cols.set_xticklabels([])\n",
        "                cols.set_yticklabels([])\n",
        "                \n",
        "            i=i+1\n",
        "        \n",
        "        \n",
        "    fig.set_size_inches(ncols*2.5,nrows*2.5)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "model = net2\n",
        "plot(temp_rem(model,Layer_Name,input_img),Num_Filters,img_original)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1MSQY72znLY"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYTTTeHTzk4Z"
      },
      "source": [
        " Describe some of the convolutional feature maps for certain images. What do you think they are representing? Do deeper convolutions result in different feature representations? (200 words)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNkJJXyw2EJj"
      },
      "source": [
        "visualization_discuss = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-el6vZazvsX"
      },
      "source": [
        "# Part 4: Deep Learning, Deep Thinking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ww0XUthvp1J"
      },
      "source": [
        "Okay, so you all just solved a classification task using the CIFAR Dataset. Before we move ahead, please read the following to articles. \n",
        " https://excavating.ai/ and https://medium.com/analytics-vidhya/an-introduction-to-fairness-in-machine-learning-62ef827e0020 (explains the fundamentals of measuring fairness in machine learning models).\n",
        " \n",
        "What do these readings suggest? There may be problems with unbalanced data and biases present in data. Now, go back and reflect on what you just did. Did you consider these problems when you designed your convnet? If so, how? If not, how could you consider them in the future? Write your thoughts (about 150 words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8WrSAEHv6V-"
      },
      "source": [
        "bias_response = '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAgCpqL0wFr0"
      },
      "source": [
        "It's time to see what those implications are on the models you just trained. <br>\n",
        "\n",
        "> Report the results of the independence and separation criteria you just read about in the medium article i.e report the accuracy for each class (independence) and report the false positive and false negative for each class (separation). <br>You can write separate code for implementing this. \n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqaANK34Qsb2"
      },
      "source": [
        "independence_accuracy = ...\n",
        "false_pos = ...\n",
        "false_neg = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWFKVVaLz2bs"
      },
      "source": [
        "# Part 5: Better Know Your Pod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kY3cvc-N4IbK"
      },
      "source": [
        "#@markdown Write about the heroes or rolemodels of two of your pod members. Why did they choose them? Which accomplishments or traits do they admire about them? (~100 words each)\n",
        "import time\n",
        "try:t4;\n",
        "except NameError: t4 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEcY5P7S0CeI"
      },
      "source": [
        "know_your_pod_1 = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAYb3dTP0IMC"
      },
      "source": [
        "know_your_pod_2 = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyHy54ZxPjPt"
      },
      "source": [
        "# Submit your responses\n",
        "Please run the following cell and then press \"Submit\" so we can record your responses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAiufZ39Lpq8",
        "cellView": "form"
      },
      "source": [
        "\n",
        "#@markdown #Run Cell to Show Airtable Form\n",
        "#@markdown Confirm your answers, upload your screenshots, paste the notebook link and then click \"Submit\". If you have any issues, submit your answers manually here: https://airtable.com/shrTQeQ67ZsllnT39\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import urllib.parse\n",
        "from IPython.display import IFrame\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "def prefill_form(src, fields: dict):\n",
        "  '''\n",
        "  src: the original src url to embed the form\n",
        "  fields: a dictionary of field:value pairs,\n",
        "  e.g. {\"pennkey\": my_pennkey, \"location\": my_location}\n",
        "  '''\n",
        "  prefills = \"&\".join([\"prefill_%s=%s\"%(key, quote_plus(fields[key]) if isinstance(fields[key], str) else fields[key]) for key in fields])\n",
        "  src = src + prefills\n",
        "  src = \"+\".join(src.split(\" \"))\n",
        "  return src\n",
        "\n",
        "\n",
        "#autofill time if it is not present\n",
        "try: t0;\n",
        "except NameError: t0 = time.time()\n",
        "try: t1;\n",
        "except NameError: t1 = time.time()\n",
        "\n",
        "\n",
        "#autofill fields if they are not present\n",
        "#a missing pennkey and pod will result in an Airtable warning\n",
        "#which is easily fixed user-side.\n",
        "try: my_pennkey;\n",
        "except NameError: my_pennkey = \"\"\n",
        "\n",
        "try: my_email;\n",
        "except NameError: my_email = \"\"\n",
        "\n",
        "try: my_pod;\n",
        "except NameError: my_pod = \"Select\"\n",
        "\n",
        "try: ffn_discussion;\n",
        "except NameError: ffn_discussion = \"\"\n",
        "\n",
        "try: cnn_discussion;\n",
        "except NameError: cnn_discussion = \"\"\n",
        "\n",
        "try: visualization_discuss;\n",
        "except NameError: visualization_discuss = \"\"\n",
        "\n",
        "try: know_your_pod_1;\n",
        "except NameError: know_your_pod_1 = \"\"\n",
        "\n",
        "try: know_your_pod_2;\n",
        "except NameError: know_your_pod_2 = \"\"\n",
        "\n",
        "try: bias_response;\n",
        "except NameError: bias_response = \"\"\n",
        "\n",
        "times = np.array([t1])-t0\n",
        "\n",
        "fields = {\"pennkey\": my_pennkey,\n",
        "          \"pod\": my_pod,\n",
        "          \"email\": my_email,\n",
        "          \"ffn_discussion\": ffn_discussion,\n",
        "          \"cnn_discussion\": cnn_discussion,\n",
        "          \"visualization_discuss\":visualization_discuss,\n",
        "          \"know_your_pod_1\":know_your_pod_1,\n",
        "          \"know_your_pod_2\":know_your_pod_2,\n",
        "          \"bias_response\":bias_response,\n",
        "          \"cumulative_times\": times}\n",
        "\n",
        "src = \"https://airtable.com/embed/shrTQeQ67ZsllnT39?\"\n",
        "#now instead of the original source url, we do: src = prefill_form(src, fields)\n",
        "display(IFrame(src = prefill_form(src, fields), width = 800, height = 400))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}